# 3D-Reconstruction-using-Structure-From-Motion

### Dataset
SFM Quality Benchmarking:   
[Herz-Jesus-P25](https://github.com/openMVG/SfM_quality_evaluation/tree/master/Benchmarking_Camera_Calibration_2008/Herz-Jesus-P25)

### Intrinsic Parameters (K)
2759.48;0;1520.69;  
0;2764.16;1006.81;  
0;0;1  

## Implementation Details
### Step-1: Keypoint Detection:
Using SIFT keypoint detection to extract the most important features from both the
images. Using SURF gave a higher reprojection error.
### Step-2 Image Matching:
#### Approach-1: FLANN Based Matcher using Lowe of 0.6 was the most effective choice
among the other options.
Total good matches in this image: 1755

#### Approach-2: BruteForce Matcher
Total matches: 3638 [showing only 1000 matches in the picture]

#### Approach-3: Deep features:
Using deep features and one-one matching,solving with the hungarian algorithm gave a
loss of 48.6. The method used for the fundamental matrix is the LMEDS algorithm.

### Step -3 Calculate Fundamental matrix
The best match points will be used to estimate the fundamental matrix using RANSAC and
LMEDS. Based on my dataset, LMEDS and RANSAC gave lower error

### Step-4 Estimate Essential Matrix
The Essential matrix was calculated using the formula on the right. Inverse of the intrinsic matrix was calculated and E was calculated accordingly.

### Step-5 Plot camera poses
I have calculated the rotation and translation matrices through Single Value Decomposition on the Essential Matrix using the belowformula.
The rotation matrix is laterconverted into Rotation vector and theta using Rodrigues function inOpenCV. I used Blender to simulate the camera pose with the Rotation vector and angle. The scale of the cube in the picture is (1.0,1.0,1.0).

### Step-6 Depth Estimation using OpenCV

### Step-7 Epipolar Geometry
The fundamental matrix was used to calculate the epilines using the function cv2.computeCorrespondEpilines.

### Step-8 Triangulation
With the help of intrinsic camera parameters, rotation, translation(extrinsic), Using the triangulatepoints function which uses DLT internally, homogeneous 3D points were calculated. Removing the unnecessary matches though gives a less error, my point cloud does not contain many 3D points initially. Below are few of the visualizations from meshlab. I modified the code to only include points that contain the mask generated by the fundamental matrix.

### Step-9 Evaluation: 

#### Best reprojection error scenario:
SIFT Keypoint detection + FLANN Matcher, Loweâ€™s raio : 0.6, Fundamental Matrix : RANSAC, LMEDS
##### Ply file header format:
ply  
format ascii 1.0  
element vertex 3638  
property float x  
property float y  
property float z  
end_header  

![alt text](https://github.com/MadHatter01/3D-Reconstruction-using-Structure-From-Motion/blob/master/image_files/snapshot1.PNG?raw=true)

#### Reprojection errors:
I have calculated the reprojection errors by applying the projection matrix to the 3D
points and applying the affine transformations. The 2D homogeneous points were
calculated, they were later translated to non homogeneous points. These points were
compared with the original 2D points of image 2. The reprojection error was estimated
using the Root Mean Squared Error formula (Below).

![alt text](https://github.com/MadHatter01/3D-Reconstruction-using-Structure-From-Motion/blob/master/image_files/formula3.PNG?raw=true)

![alt text](https://github.com/MadHatter01/3D-Reconstruction-using-Structure-From-Motion/blob/master/image_files/snapshot2.PNG?raw=true)

### Evaluation Tables
The following table consists of values for a few pairs of stereo images:  

![alt text](https://github.com/MadHatter01/3D-Reconstruction-using-Structure-From-Motion/blob/master/image_files/eval_table.PNG?raw=true)

For a pair of stereo image (0000, 0001):  

![alt text](https://github.com/MadHatter01/3D-Reconstruction-using-Structure-From-Motion/blob/master/image_files/eval_table2.PNG?raw=true)
